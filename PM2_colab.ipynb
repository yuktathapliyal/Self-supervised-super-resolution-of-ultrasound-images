{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PM2_github_final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2Qf5jVrU6qAz",
        "YLHHCvBa676s",
        "BGLdPJns-Ome",
        "bGYN_jNDU_AI"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Yb0hXeX46pP",
        "outputId": "352c17f5-84b7-44e8-e00a-86987689fe7e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdGsm9_b61BW",
        "outputId": "f501793f-313b-4900-b48a-d53f5c3fd175"
      },
      "source": [
        "!pip install tensorflow_addons"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 23.9 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1 MB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Qf5jVrU6qAz"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlrVj2Ox6gYY"
      },
      "source": [
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import pathlib\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import timeit\n",
        "import skimage\n",
        "from skimage.util import random_noise\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "from time import strftime, localtime\n",
        "from scipy.ndimage import filters, measurements, interpolation\n",
        "from math import pi\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# from torchsummary import summary\n",
        "import time\n",
        "from PIL import Image\n",
        "import scipy.io as sio\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.nn import functional as F\n",
        "from scipy.ndimage import measurements, interpolation\n",
        "from torch.utils.data import Dataset\n",
        "import random\n",
        "import pywt\n",
        "import keras\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose,\\\n",
        "                                    GlobalAveragePooling2D, AveragePooling2D, MaxPool2D, UpSampling2D,\\\n",
        "                                    BatchNormalization, Activation, ReLU, LeakyReLU, Flatten, Dense, Input,\\\n",
        "                                    Add, Multiply, Concatenate, Softmax\n",
        "from tensorflow.keras import initializers, regularizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.activations import softmax, sigmoid\n",
        "from keras.applications.vgg19 import VGG19\n",
        "tf.keras.backend.set_image_data_format('channels_last')\n",
        "import keras.backend as K"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLHHCvBa676s"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpgvSkFe7CPB"
      },
      "source": [
        "def generator():\n",
        "  input = Input(shape=(None, None, 1), batch_size=3)\n",
        "  c_1 = tfa.layers.SpectralNormalization(Conv2D(filters = 64, kernel_size=7, strides=1, padding='valid',use_bias=False))(input)\n",
        "  c_2 = tfa.layers.SpectralNormalization(Conv2D(filters = 64, kernel_size=5, strides=1, padding='valid',use_bias=False))(c_1)\n",
        "  c_3 = tfa.layers.SpectralNormalization(Conv2D(filters = 64, kernel_size=3, strides=1, padding='valid',use_bias=False))(c_2)\n",
        "  c_4 = tfa.layers.SpectralNormalization(Conv2D(filters = 64, kernel_size=1, strides=1, padding='valid',use_bias=False))(c_3)\n",
        "  c_5 = tfa.layers.SpectralNormalization(Conv2D(filters = 64, kernel_size=1, strides=1, padding='valid',use_bias=False))(c_4)\n",
        "  c_6 = tfa.layers.SpectralNormalization(Conv2D(filters =1, kernel_size=1, strides=2, padding='valid',use_bias=False))(c_5)\n",
        "  return Model(inputs = input, outputs = c_6)\n",
        "\n",
        "def discriminator():\n",
        "  input = Input(shape = (None,None,3))\n",
        "  l = tfa.layers.SpectralNormalization(Conv2D(filters=64, kernel_size=7,use_bias=True))(input)\n",
        "  for _ in range(1,6):\n",
        "    l = tfa.layers.SpectralNormalization(Conv2D(filters=64, kernel_size=1,use_bias=True))(l)\n",
        "    l = BatchNormalization()(l)\n",
        "    l = ReLU()(l)\n",
        "  l = tfa.layers.SpectralNormalization(Conv2D(filters=1, kernel_size=1,use_bias=True))(l)\n",
        "  out = sigmoid(l)\n",
        "  return Model(inputs = input, outputs = out)\n",
        "\n",
        "def d_loss(real_output, fake_output):\n",
        "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "  total_loss = real_loss + fake_loss\n",
        "  return total_loss\n",
        "\n",
        "def g_loss(fake_output):\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "generator = generator()\n",
        "discriminator = discriminator()\n",
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate = 2e-4, beta_1=0.5, beta_2=0.999)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate = 2e-4, beta_1=0.5, beta_2=0.999)\n",
        "\n",
        "class DWT_downsampling(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        \"\"\"\n",
        "        Chintan, (2021) Image Denoising using Deep Learning [Github]. \n",
        "        https://github.com/chintan1995/Image-Denoising-using-Deep-Learning/blob/main/Models/MWCNN_256x256.ipynb\n",
        "        \"\"\"\n",
        "        \n",
        "    def call(self, x):\n",
        "        \n",
        "        x1 = x[:, 0::2, 0::2, :] #x(2i−1, 2j−1)\n",
        "        x2 = x[:, 1::2, 0::2, :] #x(2i, 2j-1)\n",
        "        x3 = x[:, 0::2, 1::2, :] #x(2i−1, 2j)\n",
        "        x4 = x[:, 1::2, 1::2, :] #x(2i, 2j)   \n",
        "\n",
        "        x_LL = x1 + x2 + x3 + x4\n",
        "        x_LH = -x1 - x3 + x2 + x4\n",
        "        x_HL = -x1 + x3 - x2 + x4\n",
        "        x_HH = x1 - x3 - x2 + x4\n",
        "\n",
        "        return Concatenate(axis=-1)([x_LL, x_LH, x_HL, x_HH])\n",
        "\n",
        "class IWT_upsampling(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Chintan, (2021) Image Denoising using Deep Learning [Github]. \n",
        "    https://github.com/chintan1995/Image-Denoising-using-Deep-Learning/blob/main/Models/MWCNN_256x256.ipynb\n",
        "    \"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        \n",
        "    def call(self, x):\n",
        "       \n",
        "        x_LL = x[:, :, :, 0:x.shape[3]//4]\n",
        "        x_LH = x[:, :, :, x.shape[3]//4:x.shape[3]//4*2]\n",
        "        x_HL = x[:, :, :, x.shape[3]//4*2:x.shape[3]//4*3]\n",
        "        x_HH = x[:, :, :, x.shape[3]//4*3:]\n",
        "\n",
        "        x1 = (x_LL - x_LH - x_HL + x_HH)/4\n",
        "        x2 = (x_LL - x_LH + x_HL - x_HH)/4\n",
        "        x3 = (x_LL + x_LH - x_HL - x_HH)/4\n",
        "        x4 = (x_LL + x_LH + x_HL + x_HH)/4 \n",
        "\n",
        "        y1 = K.stack([x1,x3], axis=2)\n",
        "        y2 = K.stack([x2,x4], axis=2)\n",
        "        shape = K.shape(x)\n",
        "        return K.reshape(K.concatenate([y1,y2], axis=-1), K.stack([shape[0], shape[1]*2, shape[2]*2, shape[3]//4]))\n",
        "\n",
        "class Conv_block(tf.keras.layers.Layer):\n",
        "    def  __init__(self, num_filters=64, kernel_size=3, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_filters=num_filters\n",
        "        self.kernel_size=kernel_size\n",
        "        self.conv_1 = Conv2D(filters=self.num_filters, kernel_size=self.kernel_size, padding='same')\n",
        "        self.conv_2 = Conv2D(filters=self.num_filters, kernel_size=self.kernel_size, padding='same')\n",
        "        self.conv_3 = Conv2D(filters=self.num_filters, kernel_size=self.kernel_size, padding='same')\n",
        "        self.conv_4 = Conv2D(filters=self.num_filters, kernel_size=self.kernel_size, padding='same')\n",
        "\n",
        "    \n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'num_filters': self.num_filters,\n",
        "            'kernel_size':self.kernel_size\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def call(self, X):\n",
        "        X = self.conv_1(X)\n",
        "        \n",
        "        X = ReLU()(X)\n",
        "        X = self.conv_2(X)\n",
        "        \n",
        "        X = ReLU()(X)\n",
        "        X = self.conv_3(X)\n",
        "        \n",
        "        X = ReLU()(X)\n",
        "\n",
        "        X = self.conv_4(X)\n",
        "        X = ReLU()(X)\n",
        "\n",
        "        return X\n",
        "\n",
        "def build_model():\n",
        "  input = Input(shape=(None, None, 3))                              # Output Filters = 3\n",
        "\n",
        "  cb_1 = Conv_block(num_filters = 64)(input)                        # Output Filters = 64\n",
        "\n",
        "  dwt = DWT_downsampling()(cb_1)                                    # Output Filters = 4 x 64 = 256\n",
        "\n",
        "  cb_2 = Conv_block(num_filters=64)(dwt)                            # Output Filters = 64\n",
        "\n",
        "  c_1 = Conv2D(filters = 256, kernel_size=3, strides=1, padding='same', activation='relu')(cb_2)\n",
        "                                                                    # Output Filters = 256\n",
        "\n",
        "  iwt = IWT_upsampling()(c_1)                                      # Output Filters = 256 / 4 = 64\n",
        "\n",
        "  cb_3 = Conv_block(num_filters=64)(Add()([iwt, cb_1]))             # Output Filters = 64\n",
        "\n",
        "  c_2 = Conv2D(filters = 3, kernel_size=3, strides=1, padding='same', activation='linear')(cb_3)\n",
        "                                                                    # Output Filters = 3\n",
        "  output = tf.keras.layers.Add()([c_2, input])\n",
        "\n",
        "  return Model(inputs = input, outputs = output)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGLdPJns-Ome"
      },
      "source": [
        "# Data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHyfZ1di-b6r"
      },
      "source": [
        "def load_img(img_path, return_data_type = 'float32'):\n",
        "    \"\"\"\n",
        "    Takes input image and returns a return_data_type array\n",
        "    \"\"\"\n",
        "    image = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)                # Read image                                                                                                                                      \n",
        "    if len(image.shape) == 3:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)                # BGR -> RGB\n",
        "    else:\n",
        "        image = np.stack((image,) * 3, axis=-1)                       # Grayscale, channel 1 -> channel 3\n",
        "    if image.shape[0] == 1 or image.shape[0] == 3:\n",
        "        image = np.moveaxis(image, 0, -1)\n",
        "\n",
        "    image = image.astype(return_data_type)       \n",
        "    # np.finfo(img.dtype)\n",
        "    # finfo(resolution=1e-06, min=-3.4028235e+38, max=3.4028235e+38, dtype=float32)\n",
        "    return image\n",
        "\n",
        "def add_noise(image, sigma):\n",
        "    shape = image.shape\n",
        "\n",
        "    noise = np.random.normal(0, sigma, (shape))           # random.normal(loc(mean)=0.0, scale(std)=1.0,\n",
        "                                                                     # size(output shape)=None)\n",
        "    noise = noise.astype('float32')                                  # Check image dtype before adding\n",
        "    noisy = np.clip((image + noise), 0, 255)                         # We clip negative values and set them to zero \n",
        "                                                                     # and values over 255 are clipped to 255.\n",
        "    return noisy\n",
        "\n",
        "def image_crop(img_list, crop_size, leave_as_prob, shear_scale_prob, center_crop_prob):\n",
        "  num_imgs = len(img_list)\n",
        "  img_h, img_w, _ = img_list[0].shape\n",
        "  for i in range(num_imgs):\n",
        "    img_list[i] = np.array(img_list[i], dtype=np.float32)\n",
        "  \n",
        "  random_chooser = np.random.rand()\n",
        "  random_augment = np.random.rand()\n",
        "\n",
        "  if random_chooser < leave_as_prob:\n",
        "    mode = 'leave_as_is'\n",
        "  else:\n",
        "    mode = 'random_augment'\n",
        "\n",
        "  if mode == 'leave_as_is':\n",
        "    for i in range(num_imgs):\n",
        "      img_list[i] = img_list[i]\n",
        "  else:\n",
        "    if random_augment > shear_scale_prob:\n",
        "      shear_x = np.random.randn()*0.25\n",
        "      shear_y = np.random.randn()*0.25\n",
        "      scale_x = np.random.randn()*0.15\n",
        "      scale_y = np.random.randn()*0.15\n",
        "      transform_matrix = np.array([[1+scale_x, shear_x, 0.0],[shear_y, 1+scale_y, 0.0]])\n",
        "      transform_matrix = transform_matrix.astype(img_list[0].dtype)\n",
        "      for i in range(num_imgs):\n",
        "        img_list[i] = cv2.warpAffine(img_list[i], transform_matrix, (img_w,img_h))      \n",
        "    else:\n",
        "      if random_chooser > center_crop_prob:\n",
        "        if img_h > crop_size:\n",
        "          start_h = int((img_h - crop_size)/2)\n",
        "          end_h = int(start_h + crop_size)\n",
        "          for i in range(num_imgs):\n",
        "            img_list[i] = img_list[i][start_h:end_h, :, :]\n",
        "        if img_w > crop_size:\n",
        "          start_w = int((img_w-crop_size)/2)\n",
        "          end_w = int(start_w + crop_size)\n",
        "          for i in range(num_imgs):\n",
        "            img_list[i] = img_list[i][:, start_w: end_w, :]\n",
        "      else:\n",
        "          while (img_h - 1 < crop_size) or (img_w - 1 < crop_size):\n",
        "            crop_size -=4\n",
        "\n",
        "          w_crop_diff = img_w - crop_size\n",
        "          h_crop_diff = img_h - crop_size\n",
        "\n",
        "          top_left_x_coordinate = np.random.randint(0, w_crop_diff)\n",
        "          top_left_y_coordinate = np.random.randint(0, h_crop_diff)\n",
        "\n",
        "          X2_img_x = int(2*top_left_x_coordinate + crop_size/2)\n",
        "          X2_img_y = int(2*top_left_y_coordinate + crop_size/2)   \n",
        "          \n",
        "          for i in range(num_imgs):\n",
        "            img_list[i] = img_list[i][top_left_y_coordinate:top_left_y_coordinate+crop_size, top_left_x_coordinate:top_left_x_coordinate+crop_size,:]\n",
        "\n",
        "    random_rot = random.randint(0,7)\n",
        "    for i in range(num_imgs):\n",
        "      img_list[i] = np.rot90(img_list[i], random_rot, axes = (0,1))\n",
        "    if random_rot > 3 :\n",
        "      for i in range(num_imgs):\n",
        "        img_list[i] = np.fliplr(img_list[i])\n",
        "\n",
        "  for i in range(num_imgs):\n",
        "    if img_list[i].shape[0]%2 != 0:\n",
        "      img_list[i] = img_list[i][:-1,:,:]\n",
        "    if img_list[i].shape[1]%2 !=0:\n",
        "      img_list[i] = img_list[i][:,:-1,:]\n",
        "\n",
        "  return img_list\n",
        "\n",
        "def swap_axis(image):\n",
        "\n",
        "  return np.transpose(image, axes=[3,1,2,0]) if type(image) == np.ndarray else tf.transpose(image, perm=[3,1,2,0])\n",
        "  \n",
        "def parent_to_child(hr_parent, scale_factor, kernel):\n",
        "  \"\"\"\n",
        "  This function takes the hr_parent and first downsamples it to create lr_child and \n",
        "  then adds noise if noise_flag is True.\n",
        "  Finally, the image is upsampled to feed into the network.\n",
        "  \"\"\"\n",
        "  scale_down = 1/scale_factor\n",
        "  if len(hr_parent.shape) == 4:\n",
        "    hr_parent = np.squeeze(hr_parent, axis=0)\n",
        "  else:\n",
        "    hr_parent = hr_parent\n",
        "  input_shape = hr_parent.shape\n",
        "  # print(hr_parent.shape)\n",
        "\n",
        "  output_shape = np.uint(np.ceil(np.array(input_shape))*np.array(scale_down))\n",
        "\n",
        "  lr_child = numeric_kernel(hr_parent, kernel, scale_down, output_shape)\n",
        "  # print(lr_child.shape)\n",
        "  lr_child = add_noise(lr_child, sigma)\n",
        "\n",
        "  lr_child = cv2.resize(lr_child, (hr_parent.shape[1], hr_parent.shape[0]), interpolation = cv2.INTER_CUBIC)\n",
        "  # print(lr_child.shape)\n",
        "\n",
        "  return np.expand_dims(lr_child, axis=0)\n",
        "\n",
        "def hr_lr_generator(image, \n",
        "                    scale_factor, \n",
        "                    final_kernel,\n",
        "                    shear_scale_prob,\n",
        "                    leave_as_prob,\n",
        "                    center_crop_prob,\n",
        "                    crop_size):\n",
        "\n",
        "  \"\"\"\n",
        "  Generator to simply return hr_parent and lr_child as a pair\n",
        "  \"\"\"\n",
        "  while True:\n",
        "    \n",
        "    hr_parent_list = image_crop([image],\n",
        "                               crop_size,\n",
        "                               leave_as_prob,\n",
        "                               shear_scale_prob,\n",
        "                               center_crop_prob)\n",
        "    hr_parent = hr_parent_list[0]\n",
        "    lr_child = parent_to_child(hr_parent, scale_factor, final_kernel)\n",
        "  \n",
        "    if len(lr_child.shape) == 4:\n",
        "      x = lr_child\n",
        "    else:\n",
        "      x = np.expand_dims(lr_child, axis=0)\n",
        "\n",
        "    if len(hr_parent.shape) == 4:\n",
        "      y = hr_parent\n",
        "    else:\n",
        "      y = np.expand_dims(hr_parent, axis = 0)\n",
        "    yield x, y\n",
        "\n",
        "def get_gradual_factors(SR_factor, gradual_increase_value):\n",
        "  gradual_SR_list = [SR_factor]\n",
        "  sr_fact = SR_factor/gradual_increase_value\n",
        "  while (sr_fact) != 1:\n",
        "    gradual_SR_list.append(int(sr_fact))\n",
        "    sr_fact = sr_fact/gradual_increase_value\n",
        "  gradual_SR_list.reverse()\n",
        "  return gradual_SR_list\n",
        "\n",
        "def get_images_paths(input_pd):\n",
        "  root = pathlib.Path(input_pd)\n",
        "  img_paths = list(sorted(root.rglob('*.png')))\n",
        "  img_paths_list = [str(path) for path in img_paths]\n",
        "  \n",
        "  return img_paths_list\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGYN_jNDU_AI"
      },
      "source": [
        "# Kernel post-procesing\n",
        "\n",
        "The post-processing here has been used as in the official code of KernelGAN, URL: https://github.com/sefibk/KernelGAN\n",
        "\n",
        "Paper: S. B. Kligler, A. Shocher, M. Irani, \"Blind Super-Resolution Kernel Estimation using an Internal-GAN\" in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, 8-14 December 2019, Vancouver, BC, Canada. pages 284-293, 2019."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htIScOOk145e"
      },
      "source": [
        "def numeric_kernel(hr_parent, kernel, scale_down, output_shape):\n",
        "  out_im = np.zeros_like(hr_parent)\n",
        "  # print('out_im shape', out_im.shape)\n",
        "  # print('kernel_shape', kernel.shape)\n",
        "  for channel in range(hr_parent.ndim):\n",
        "    out_im[:,:,channel] = filters.correlate(hr_parent[:,:,channel], kernel)\n",
        "  return out_im[np.round(np.linspace(0, hr_parent.shape[0] - 1 / scale_down, output_shape[0])).astype(int)[:, None],\n",
        "           np.round(np.linspace(0, hr_parent.shape[1] - 1 / scale_down, output_shape[1])).astype(int), :]\n",
        "\n",
        "def zeroize_negligible(k,n = 40):\n",
        "  k_sorted = np.sort(k.flatten())\n",
        "  k_n_min = 0.75 * k_sorted[-n - 1]\n",
        "  filtered_k = np.clip(k - k_n_min, a_min=0, a_max=100)\n",
        "  return filtered_k / filtered_k.sum()\n",
        "\n",
        "def kernel_shift(kernel, sf):\n",
        "    current_center_of_mass = measurements.center_of_mass(kernel)\n",
        "    wanted_center_of_mass = np.array(kernel.shape) // 2 + 0.5 * (np.array(sf) - (np.array(kernel.shape) % 2))\n",
        "    shift_vec = wanted_center_of_mass - current_center_of_mass\n",
        "    kernel = np.pad(kernel, np.int(np.ceil(np.max(np.abs(shift_vec)))) + 1, 'constant')\n",
        "    kernel = interpolation.shift(kernel, shift_vec)\n",
        "    return kernel\n",
        "\n",
        "def post_process_k(k, n):\n",
        "    k = k.detach().cpu().float().numpy()\n",
        "    # Zeroize negligible values\n",
        "    significant_k = zeroize_negligible(k, n)\n",
        "    # Force centralization on the kernel\n",
        "    centralized_k = kernel_shift(significant_k, sf=2)\n",
        "    # return shave_a2b(centralized_k, k)\n",
        "    return centralized_k\n",
        "\n",
        "def analytic_kernel(k):\n",
        "    \"\"\"Calculate the X4 kernel from the X2 kernel (for proof see appendix in paper)\"\"\"\n",
        "    k_size = k.shape[0]\n",
        "    # Calculate the big kernels size\n",
        "    big_k = np.zeros((3 * k_size - 2, 3 * k_size - 2))\n",
        "    # Loop over the small kernel to fill the big one\n",
        "    for r in range(k_size):\n",
        "        for c in range(k_size):\n",
        "            big_k[2 * r:2 * r + k_size, 2 * c:2 * c + k_size] += k[r, c] * k\n",
        "    # Crop the edges of the big kernel to ignore very small values and increase run time of SR\n",
        "    crop = k_size // 2\n",
        "    cropped_big_k = big_k[crop:-crop, crop:-crop]\n",
        "    # Normalize to 1\n",
        "    return cropped_big_k / cropped_big_k.sum()\n",
        "\n",
        "def save_final_kernel(k_2, img_name, i):\n",
        "    \"\"\"saves the final kernel and the analytic kernel to the results folder\"\"\"\n",
        "    if i == 0:\n",
        "      sio.savemat(os.path.join(output_pd, '%s_kernel_x2.mat' % img_name), {'Kernel': k_2})\n",
        "    else:\n",
        "      k_4 = analytic_kernel(k_2)\n",
        "      sio.savemat(os.path.join(output_pd, '%s_kernel_x4.mat' % img_name), {'Kernel': k_4})"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coV130Lo5JdV"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siwGaMifRa2J"
      },
      "source": [
        "input_pd = r'/content/gdrive/MyDrive/5. data_all/D1_X4'\n",
        "output_pd = r'/content/gdrive/MyDrive/checking'\n",
        "\n",
        "drop_lr = 0.5 #\tfactor by which the learning rate will be reduced. new_lr = lr * factor\n",
        "num_epochs = 1500 # Number of epochs to run the model per image\n",
        "sigma = 30 # Standard deviation (spread or “width”) of the normal distribution\n",
        "gradual_increase_value = 2 # Value with which the images are gradually super-resolved. This gradual increase factor is inspired by Shocher, Assaf & Cohen, Nadav & Irani, Michal. (2018). Zero-Shot Super-Resolution Using Deep Internal Learning. 3118-3126. 10.1109/CVPR.2018.00329. \n",
        "leave_as_prob = 0.3 # This is the probability associated with augmentation of hr parent. A higher leave_as_is_probability reduces probability of random augmentation in hr parent.\n",
        "shear_scale_prob = 0.6 # This the prabability associated with random shearing & scaling of HR parent during augmentations. A lower shear_scale_prob value prompts the model to increase the probability of random shearing & scaling, and vice-versa\n",
        "center_crop_prob = 1  # If center_crop_prob is small, more crops are taken from the center of the image. Else, if center_crop_prob is large, crops are taken randomly from the image, regardless of location.\n",
        "crop_size = 96 # This is the initial crop size to be considered. \n",
        "SR_factor = 4 # The is the super resolution factor.\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tkuu6_UjXAX"
      },
      "source": [
        "def predict_image(image, scale_factor):\n",
        "\n",
        "  \"\"\"\n",
        "  This function predicts the original image on the trained model.\n",
        "  It takes the original image and interpolates it by scale_factor, expands image dimesnions to 4d, takes prediction,\n",
        "  and outputs 8 bit image.\n",
        "  \"\"\"\n",
        "  image_upscaled = cv2.resize(np.float32(image), None, fx = scale_factor, fy = scale_factor, interpolation = cv2.INTER_CUBIC)\n",
        "  image_upscaled = np.expand_dims(image_upscaled, axis = 0)\n",
        "  super_image = model.predict(image_upscaled)\n",
        "  super_image = np.squeeze(super_image, axis=0)\n",
        "  super_image = cv2.convertScaleAbs(super_image)\n",
        "\n",
        "  return super_image\n",
        "\n",
        "def train_step(input_image, epoch, crop_size, leave_as_prob, shear_scale_prob, center_crop_prob):\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    original_image = input_image\n",
        "    noisy_image = add_noise(input_image, sigma)\n",
        "    cropped_img_list = image_crop([original_image,\n",
        "                                   noisy_image], \n",
        "                                  crop_size,\n",
        "                                  leave_as_prob, \n",
        "                                  shear_scale_prob, \n",
        "                                  center_crop_prob)\n",
        "                                                                                  \n",
        "    noisy_image_expand_axis = tf.expand_dims(cropped_img_list[1], axis =0)\n",
        "    noisy_image_swapped_axis = swap_axis(noisy_image_expand_axis)\n",
        "    original_image_expand_axis = tf.expand_dims(cropped_img_list[0], axis = 0)\n",
        "    gen_output = generator(noisy_image_swapped_axis, training=True)\n",
        "    gen_output = swap_axis(gen_output)\n",
        "    disc_real_output = discriminator(original_image_expand_axis, training = True)\n",
        "    disc_generated_output = discriminator(gen_output, training = True)\n",
        "    gen_loss = g_loss(disc_generated_output)\n",
        "    disc_loss = d_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "  generator_gradients = gen_tape.gradient(gen_loss,\n",
        "                                          generator.trainable_variables)\n",
        "  \n",
        "  discriminator_gradients = disc_tape.gradient(disc_loss,\n",
        "                                               discriminator.trainable_variables)\n",
        "  \n",
        "  generator_optimizer.apply_gradients(zip(generator_gradients,\n",
        "                                          generator.trainable_variables))\n",
        "  \n",
        "  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
        "                                              discriminator.trainable_variables))\n",
        "  \n",
        "  # with summary_writer.as_default():\n",
        "    # tf.summary.scalar('gen_total_loss', gen_loss, step=epoch)\n",
        "    # tf.summary.scalar('disc_loss', disc_loss, step=epoch)\n",
        "\n",
        "def fit(input_image, epochs, crop_size, leave_as_prob, shear_scale_prob, center_crop_prob):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    # Training step\n",
        "    train_step(input_image, epoch, crop_size, leave_as_prob, shear_scale_prob, center_crop_prob)\n",
        "    \n",
        "    # Saving (checkpointing) the model every 20 epochs\n",
        "    # if (epoch + 1) % 20 == 0:\n",
        "    # checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "    print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
        "                                                        time.time()-start))\n",
        "  # checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "callback_list = [tf.keras.callbacks.ReduceLROnPlateau(monitor = 'loss',\n",
        "                                                      factor = drop_lr,\n",
        "                                                      patience = 100,\n",
        "                                                      verbose = 0,\n",
        "                                                      mode = 'min',\n",
        "                                                      min_delta = 0.001,\n",
        "                                                      cooldown = 20,\n",
        "                                                      min_lr = 0.00000001),\n",
        "                  tf.keras.callbacks.EarlyStopping(monitor = 'loss',\n",
        "                                                   min_delta = 0.0001,\n",
        "                                                   patience = 350,\n",
        "                                                   verbose = 1,\n",
        "                                                   mode = 'min')\n",
        "]\n",
        "\n",
        "mae_loss_object = tf.keras.losses.MeanAbsoluteError()\n",
        "vgg19 = VGG19(include_top=False, weights='imagenet')\n",
        "vgg19.trainable = False\n",
        "for l in vgg19.layers:\n",
        "    l.trainable = False\n",
        "vgg_model = Model(inputs=vgg19.input, outputs=vgg19.get_layer('block1_conv2').output)\n",
        "vgg_model.trainable = False\n",
        "model = build_model()\n",
        "def custom_loss(y_true, y_pred):    \n",
        "    mae_loss = mae_loss_object(y_true, y_pred)\n",
        "    vgg_loss = K.mean(K.square(vgg_model(y_true) - vgg_model(y_pred)))\n",
        "    vgg_loss_adjusted = (1 - (1/(1+vgg_loss)))*10\n",
        "    \n",
        "    return mae_loss + vgg_loss_adjusted\n",
        "\n",
        "gradual_SR_list = get_gradual_factors(SR_factor, gradual_increase_value)\n",
        "\n",
        "print('Scaling gradually in order:', gradual_SR_list)\n",
        "\n",
        "scale_fact = gradual_increase_value\n",
        "\n",
        "date_time = strftime('_%b_%d_%H_%M_%S', localtime())\n",
        "super_dir = output_pd + '/' + date_time + '/' + '_super'\n",
        "#avg_dir = output_pd + '/' + date_time + '/' + '_avg'\n",
        "#median_dir = output_pd + '/' + date_time + '/' + '_median'\n",
        "\n",
        "os.makedirs(super_dir)\n",
        "#os.makedirs(avg_dir)\n",
        "#os.makedirs(median_dir)\n",
        "start = timeit.default_timer()\n",
        "\n",
        "for file in os.listdir(input_pd):\n",
        "  \n",
        "  image_path = os.path.join(input_pd, '%s' %file)\n",
        "  image = load_img(image_path)\n",
        "\n",
        "  image_tf = tf.convert_to_tensor(image, dtype = tf.float32)\n",
        "\n",
        "  tf.keras.backend.clear_session()\n",
        "  fit(image_tf, 3000, crop_size, leave_as_prob, shear_scale_prob, center_crop_prob)\n",
        "\n",
        "  delta = torch.Tensor([1.]).unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
        "  for layer_idx, layer in enumerate(generator.layers):\n",
        "    if layer_idx == 0:\n",
        "      pass\n",
        "    else:\n",
        "     for weight_idx, weight in enumerate(layer.get_weights()):\n",
        "      if weight_idx == 0:\n",
        "        \n",
        "        weight = np.transpose(weight, axes=[3,2,0,1])\n",
        "        weight = torch.from_numpy(weight)\n",
        "        curr_k = F.conv2d(delta, weight, padding = 13-1) if layer_idx == 1 else F.conv2d(curr_k, weight)\n",
        "       \n",
        "  curr_k = curr_k.squeeze().flip([0,1])\n",
        "\n",
        "  final_kernel = post_process_k(curr_k,n = 40)\n",
        "\n",
        "  tf.keras.backend.clear_session()\n",
        "  print('starting training for', file)\n",
        "  tf.keras.backend.clear_session()\n",
        "  model.compile(loss = custom_loss, optimizer = Adam(learning_rate=0.001))\n",
        "  for i in range(len(gradual_SR_list)):\n",
        "    print('checkpoint 1')\n",
        "    if i == 0:\n",
        "      k = final_kernel \n",
        "    else:\n",
        "      k = analytic_kernel(final_kernel)\n",
        "      \n",
        "    img_name = str(file).split(sep='.')\n",
        "    img_name = img_name[0]\n",
        "    save_final_kernel(k, img_name, i)\n",
        "\n",
        "    if len(image.shape) == 4:\n",
        "      image = np.squeeze(image, axis = 0)\n",
        "    else:\n",
        "      image = image\n",
        "    print('checkpoint 2')\n",
        "    \n",
        "    model.fit(hr_lr_generator(image, \n",
        "                              scale_factor=scale_fact, \n",
        "                              final_kernel = k,\n",
        "                              shear_scale_prob = shear_scale_prob,\n",
        "                              leave_as_prob= 0.2,\n",
        "                              center_crop_prob = center_crop_prob,\n",
        "                              crop_size = 96),\n",
        "              batch_size = 1,\n",
        "              epochs = num_epochs,\n",
        "              verbose =1, \n",
        "              callbacks = callback_list, \n",
        "              steps_per_epoch = 1)\n",
        "    \n",
        "    super_image = predict_image(image, scale_factor = scale_fact)\n",
        "    \n",
        "    image = super_image\n",
        "  plt.imsave(os.path.join(super_dir,'%s' %file), super_image, format = 'png')\n",
        "  # plt.imsave(os.path.join(avg_dir,'%s' %file), avg, format = 'png')\n",
        "  # plt.imsave(os.path.join(median_dir,'%s' %file), median, format = 'png')\n",
        "\n",
        "  tf.keras.backend.clear_session()\n",
        "  \n",
        "\n",
        "print('Done!!!')\n",
        "stop = timeit.default_timer()\n",
        "\n",
        "print('Time take for all images is', stop-start, 'seconds')\n",
        "SR_factor = None\n",
        "input_pd = None\n",
        "output_pd = None"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}