{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "New_Copy_of_EvaluationOfImg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM-tpI3Acnrk",
        "outputId": "9f4d1b67-5420-42da-bdfb-93841547027a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVt4_D6UQl6x"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "import pathlib\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "!pip install lpips\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import lpips\n",
        "from google.colab.patches import cv2_imshow\n",
        "trans = transforms.ToTensor()\n",
        "import tensorflow as tf\n",
        "import glob"
      ],
      "metadata": {
        "id": "ATbxEmx-6lSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_3Qy5Cg4sSW"
      },
      "source": [
        "def get_img_paths(predict_dir,original_dir):\n",
        "  predict_root = pathlib.Path(predict_dir)\n",
        "  predict_paths = list(sorted(predict_root.rglob(\"*.png*\")))\n",
        "  predict_paths_lst = [str(path) for path in predict_paths]\n",
        "\n",
        "  original_root = pathlib.Path(original_dir)\n",
        "  original_paths = list(sorted(original_root.rglob(\"*.png*\")))\n",
        "  original_paths_lst = [str(path) for path in original_paths]\n",
        "\n",
        "  original_array = np.asarray(original_paths_lst)\n",
        "  predict_array = np.asarray(predict_paths_lst)\n",
        "  return predict_array, original_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKlrDwKpVoc0"
      },
      "source": [
        "def evaluate_final(test_data_path, test_target_path):\n",
        "  num_test_imgs = len(test_data_path)\n",
        "  num_losses = 4\n",
        "  eval_numpy = np.zeros((len(test_data_path),4), dtype=float)\n",
        "  \n",
        "  eval_numpy = np.zeros(shape = (num_test_imgs,num_losses))\n",
        "  for itr in range(num_test_imgs):\n",
        "    test_data_img = cv2.imread(test_data_path[itr])\n",
        "    test_data_cvt = cv2.cvtColor(test_data_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    test_target_img = cv2.imread(test_target_path[itr])\n",
        "    test_target_cvt = cv2.cvtColor(test_target_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    if test_data_cvt.shape != test_target_cvt.shape:\n",
        "      test_data_cvt = cv2.resize(test_data_cvt, (test_target_cvt.shape[1],test_target_cvt.shape[0]))\n",
        "\n",
        "    psnr, SSIM,Alex_Loss, VGG_Loss = eval_metrics(test_target_cvt, test_data_cvt)\n",
        "    \n",
        "    eval_numpy[itr,0],eval_numpy[itr,1],eval_numpy[itr,2],eval_numpy[itr,3] = psnr, SSIM,Alex_Loss, VGG_Loss\n",
        "    \n",
        "  \n",
        "  return eval_numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn_alex = lpips.LPIPS(net='alex') # best forward scores\n",
        "loss_fn_vgg = lpips.LPIPS(net='vgg') # closer to \"traditional\" perceptual loss, when used for optimization\n",
        "\n",
        "def eval_metrics(img_1, img_2):\n",
        "  \n",
        "  # PSNR\n",
        "  psnr = cv2.PSNR(img_1,img_2)\n",
        "  #print('psnr:', psnr)\n",
        "  \n",
        "  \n",
        "  # SSIM\n",
        "  (score,diff) = ssim(img_1, img_2, full = True, multichannel = True)\n",
        "  # diff = (diff*255)\n",
        "  SSIM = score\n",
        "  \n",
        "  # LPIPS\n",
        "  im_1 = np.moveaxis(img_1,-1,0)\n",
        "  img1_torch = torch.tensor(im_1)\n",
        "  img1 = torch.unsqueeze(img1_torch,0)\n",
        "\n",
        "  im_2 = np.moveaxis(img_2,-1,0)\n",
        "  img2_torch = torch.tensor(im_2)\n",
        "  img2 = torch.unsqueeze(img2_torch,0)\n",
        "\n",
        "  Alex_Loss = loss_fn_alex(img1, img2)\n",
        "  VGG_loss = loss_fn_vgg(img1, img2)\n",
        "  \n",
        "  return psnr, SSIM, Alex_Loss.item(),VGG_loss.item()"
      ],
      "metadata": {
        "id": "H7-U9W8i8GS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iecMpaz1j-Q_"
      },
      "source": [
        "def losses_of_set(eval_numpy):\n",
        "  mean = np.mean(eval_numpy,axis =0)\n",
        "  var = np.var(eval_numpy,axis=0)\n",
        "\n",
        "  print('PSNR : {:0.4f} +/- {:0.4f}'.format(mean[0],var[0]))\n",
        "  print('SSIM : {:0.4f} +/- {:0.4f}'.format(mean[1],var[1]))\n",
        "  print('Alex_loss : {:0.4f} +/- {:0.4f}'.format(mean[2],var[2]))\n",
        "  print('VGG_loss : {:0.4f} +/- {:0.4f}'.format(mean[3],var[3]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTQ7HWitntzt"
      },
      "source": [
        "# Eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtP4shQhHVhN"
      },
      "source": [
        "del original_test, predict_bicubic, array_predict_paths, array_original_paths, eval_numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_test = 'Path to original images'\n",
        "predict_bicubic = 'Path to predicted images'\n",
        "array_predict_paths, array_original_paths = get_img_paths(predict_bicubic,original_test)\n",
        "eval_numpy = evaluate_final(array_predict_paths, array_original_paths)\n",
        "losses_of_set(eval_numpy)"
      ],
      "metadata": {
        "id": "XK29uQSG8K9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jxHNtYhPeOE"
      },
      "source": [
        "df = pd.DataFrame(eval_numpy, columns=['PSNR', 'SSIM', 'ALEX','VGG'])\n",
        "df.to_csv('result.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}